{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "EEo2HpJ41UwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35504e2-7dbd-4ae2-e02b-b7c2138ba90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/137.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "iFVwfbPq1X39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae39c55-185c-4d3d-c115-d586a17014a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n"
      ],
      "metadata": {
        "id": "fpor0Ydhqdla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0b9a15-ee08-4fda-e212-5198708650f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pytube import YouTube\n",
        "from glob import glob\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import PIL.Image\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from IPython.display import display, Markdown, Video\n",
        "import textwrap\n",
        "import subprocess\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "# Setup Google Gemini API\n",
        "GOOGLE_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "q4Xd-3pzSnPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHNf4-oV1CCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "590eaf49-d4d4-455d-a9db-004733c294fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video URLhttps://www.youtube.com/watch?v=irv5CbKdHOc\n",
            "LanguageSpanish\n",
            "Video downloaded to /content/Linear Algebra - Solving Systems of Equations.mp4\n",
            "FPS:---120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Frames: 100%|██████████| 4300/4300 [00:08<00:00, 516.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total key frames extracted: 12\n"
          ]
        }
      ],
      "source": [
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Function to download and preprocess video\n",
        "def download_and_preprocess_video(url):\n",
        "    # Download video at 360p resolution to reduce processing time\n",
        "    video_path = YouTube(url).streams.filter(res=\"360p\").first().download()\n",
        "    print(f\"Video downloaded to {video_path}\")\n",
        "    return video_path\n",
        "\n",
        "# Function to extract key frames from the video\n",
        "def extract_key_frames(video_path, output_directory='selected_frames', threshold=0.7):\n",
        "    # Create a directory to save the selected frames\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = 10*int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    print(\"FPS:\", fps, sep=\"---\")\n",
        "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    selected_frames = []\n",
        "    previous_frame = None\n",
        "\n",
        "    for frame_idx in tqdm(range(n_frames), desc=\"Processing Frames\"):\n",
        "        ret, img = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Process every (fps/4)th frame\n",
        "        if frame_idx % fps != 0:\n",
        "            continue\n",
        "\n",
        "        if previous_frame is not None:\n",
        "            # Structural Similarity Index (SSI) for RGB channels\n",
        "            b, g, r = cv2.split(img)\n",
        "            ssim_b, _ = ssim(previous_frame[0], b, full=True)\n",
        "            ssim_g, _ = ssim(previous_frame[1], g, full=True)\n",
        "            ssim_r, _ = ssim(previous_frame[2], r, full=True)\n",
        "\n",
        "            similarity_index = (ssim_b + ssim_g + ssim_r) / 3\n",
        "\n",
        "            if similarity_index < threshold:\n",
        "                selected_frames.append(img)\n",
        "                frame_filename = os.path.join(output_directory, f\"frame_{frame_idx:04d}.png\")\n",
        "                cv2.imwrite(frame_filename, img)\n",
        "\n",
        "        previous_frame = cv2.split(img)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    print(f\"Total key frames extracted: {len(selected_frames)}\")\n",
        "\n",
        "def clear_frames(image_directory='selected_frames'):\n",
        "\n",
        "  if os.path.exists(\"/content/output.txt\") == True:\n",
        "    out_path = \"/content/output.txt\"\n",
        "    os.remove(out_path)\n",
        "\n",
        "  if os.path.exists(\"/content/transcript.txt\") == True:\n",
        "    trans_path = \"/content/transcript.txt\"\n",
        "    os.remove(trans_path)\n",
        "\n",
        "  if os.path.exists(\"/content/latex.txt\") == True:\n",
        "    latex_path = \"/content/latex.txt\"\n",
        "    os.remove(latex_path)\n",
        "  # Specify the folder path\n",
        "  folder_path = \"/content/selected_frames\"\n",
        "\n",
        "  # List all files in the folder\n",
        "  #files = os.listdir(folder_path)\n",
        "\n",
        "  # Delete each file\n",
        "  #for file in files:\n",
        "  #    file_path = os.path.join(folder_path, file)\n",
        "  #    os.remove(file_path)\n",
        "  #print(\"Cleared\")\n",
        "  #return\n",
        "\n",
        "# Convert the selected frames to PIL format for model processing\n",
        "def convert_frames_to_pil(image_directory='selected_frames'):\n",
        "    images = []\n",
        "    for filename in sorted(glob(os.path.join(image_directory, '*.png'))):\n",
        "        img = PIL.Image.open(filename)\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "# Process and display response for each image with Gemini\n",
        "def process_image_with_gemini(image, model, instructions, prompt1, prompt2):\n",
        "    content = [instructions, prompt1, prompt2, image]\n",
        "    response = model.generate_content(content)\n",
        "    return response\n",
        "\n",
        "def transcript(video_id):\n",
        "    file = open('transcript.txt', 'a')\n",
        "    transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    # Combining the text of all transcript segments into a single string\n",
        "    for item in transcript_list:\n",
        "      file.write(item['text'])\n",
        "      file.write(\" \")\n",
        "    #transcript_text = ' '.join([item['text'] for item in transcript_list])\n",
        "\n",
        "    return\n",
        "\n",
        "# Main function to run the workflow\n",
        "def main(video_url, language, personality):\n",
        "    clear_frames()\n",
        "    video_path = download_and_preprocess_video(video_url)\n",
        "\n",
        "    video_id = video_url.split('=')[-1]\n",
        "    transcript(video_id)\n",
        "\n",
        "    extract_key_frames(video_path)\n",
        "    images = convert_frames_to_pil()\n",
        "\n",
        "    # Select Gemini Pro Vision model\n",
        "    model = genai.GenerativeModel('gemini-pro-vision')\n",
        "\n",
        "    # Instructions and prompts\n",
        "    instructions = \"Instructions: Consider the following image and answer the questions in \" + language + \" with a \" + personality + \" personality:\"\n",
        "    #prompt1 = \"What is shown in each of the images?\"\n",
        "    #prompt2 = \"Describe what is happening in the images, if there are numbers or math related symbols, please use LATEX to format them.\"\n",
        "    prompt1 = \"For each image, describe in detail: Any visible text, equations, or symbols, using LaTeX formatting where applicable. The context or subject matter being discussed or illustrated. Any diagrams, charts, or visual aids, including their significance and how they relate to the lecture content.\"\n",
        "    prompt2 = \"Additionally, offer interpretations that could link these images to lecture topics, making assumptions based on visible content. Suggest headings or captions for each image that could be used in the LaTeX document to organize the lecture notes effectively.\"\n",
        "\n",
        "    file = open('output.txt', 'a')\n",
        "    i=0\n",
        "    # Process each image with the Gemini model\n",
        "    for image in images:\n",
        "        response = process_image_with_gemini(image, model, instructions, prompt1, prompt2)\n",
        "        file.write(\"\\n-------Response: \")\n",
        "        file.write(str(i))\n",
        "        file.write(\"--------\\n\")\n",
        "        #print(\"\\n-------Response: \", i, \"--------\", \"\")\n",
        "        i = i+1\n",
        "        for text in response:\n",
        "          file.write(text.text)\n",
        "          #  print(text.text, end=\"\")\n",
        "    file.close()\n",
        "    latex_out()\n",
        "\n",
        "def latex_out():\n",
        "  modelito = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "  visualization = 'output.txt'\n",
        "\n",
        "  with open(visualization, 'r') as file:\n",
        "    visualization_s = file.read()\n",
        "  file.close()\n",
        "\n",
        "  transcriptt = 'transcript.txt'\n",
        "\n",
        "  with open(transcriptt, 'r') as file:\n",
        "    transcript_s = file.read()\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  file = open('latex.tex', 'w')\n",
        "  response = modelito.generate_content(\"The following is the transcription of an educational video:\"  + transcript_s + \"and the following is the visualization of the video in text:\" + visualization_s + \"Based on that, please output a latex file that contains the mash up of the two in a way where it looks like lecture notes, or like all the content viewed in the video, also please do not enumerate the images, please be very careful with latex formatting, write the lecture notes in\" + language + \", for example the very first line would be \\documentclass[12pt]{article}\")\n",
        "\n",
        "  for text in response:\n",
        "    file.write(text.text)\n",
        "\n",
        "  file.close()\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example YouTube video URL\n",
        "    video_url = input(\"Video URL: \") #\"https://www.youtube.com/watch?v=irv5CbKdHOc\"\n",
        "    language = input(\"Language: \")\n",
        "    personality = \"lawful and professional\"\n",
        "\n",
        "    main(video_url, language, personality)\n",
        "\n",
        "\n"
      ]
    }
  ]
}